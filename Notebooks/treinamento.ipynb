{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√© requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate==0.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate==0.21.0) (1.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from accelerate==0.21.0) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from accelerate==0.21.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate==0.21.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate==0.21.0) (2.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.21.0) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.21.0) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate==0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.25.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.25.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>materia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ol√°, como s√£o formadas as cavernas? e as estal...</td>\n",
       "      <td>Qu√≠mica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qual a diferen√ßa entre a gordura animal e a go...</td>\n",
       "      <td>Biologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Como funciona a rela√ß√£o do √¢ngulo externo do t...</td>\n",
       "      <td>Matem√°tica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(UESB BA/2017) Sejam dois conjuntos n√£o vazios...</td>\n",
       "      <td>Matem√°tica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boa tarde! Qual a rela√ß√£o das mitoc√¥ndrias com...</td>\n",
       "      <td>Biologia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto     materia\n",
       "0  ol√°, como s√£o formadas as cavernas? e as estal...     Qu√≠mica\n",
       "1  Qual a diferen√ßa entre a gordura animal e a go...    Biologia\n",
       "2  Como funciona a rela√ß√£o do √¢ngulo externo do t...  Matem√°tica\n",
       "3  (UESB BA/2017) Sejam dois conjuntos n√£o vazios...  Matem√°tica\n",
       "4  Boa tarde! Qual a rela√ß√£o das mitoc√¥ndrias com...    Biologia"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leitura da base de dados\n",
    "# Parametros adicionais sao necessarios ja que o caractere de separacao da base consisti no ¬®\n",
    "df_perguntas = pd.read_csv(\"../Dados/dados.csv\")\n",
    "df_perguntas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Qu√≠mica', 'Biologia', 'Matem√°tica', 'Hist√≥ria', 'Literatura', 'F√≠sica']\n",
      "Total de mat√©rias: 6\n"
     ]
    }
   ],
   "source": [
    "# Retirando as classes \"target\" dinamicamente, no caso as materias das perguntas\n",
    "materias = df_perguntas['materia'].unique().tolist()\n",
    "\n",
    "print(materias)\n",
    "print(f\"Total de mat√©rias: {len(materias)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qu√≠mica tem 11 Quest√µes\n",
      "Biologia tem 10 Quest√µes\n",
      "Matem√°tica tem 10 Quest√µes\n",
      "Hist√≥ria tem 10 Quest√µes\n",
      "Literatura tem 10 Quest√µes\n",
      "F√≠sica tem 10 Quest√µes\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(materias)):\n",
    "    print(f\"{materias[i]} tem {len(df_perguntas[df_perguntas.materia == materias[i]])} Quest√µes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionarios: ID -> Materia e Materia -> ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERO_MATERIAS = len(materias)\n",
    "\n",
    "dic_id_para_materia = {id:materia for id,materia in enumerate(materias)} \n",
    "dic_materia_para_id = {materia:id for id,materia in enumerate(materias)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Qu√≠mica',\n",
       " 1: 'Biologia',\n",
       " 2: 'Matem√°tica',\n",
       " 3: 'Hist√≥ria',\n",
       " 4: 'Literatura',\n",
       " 5: 'F√≠sica'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_id_para_materia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Qu√≠mica': 0,\n",
       " 'Biologia': 1,\n",
       " 'Matem√°tica': 2,\n",
       " 'Hist√≥ria': 3,\n",
       " 'Literatura': 4,\n",
       " 'F√≠sica': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_materia_para_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>materia</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ol√°, como s√£o formadas as cavernas? e as estal...</td>\n",
       "      <td>Qu√≠mica</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qual a diferen√ßa entre a gordura animal e a go...</td>\n",
       "      <td>Biologia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Como funciona a rela√ß√£o do √¢ngulo externo do t...</td>\n",
       "      <td>Matem√°tica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(UESB BA/2017) Sejam dois conjuntos n√£o vazios...</td>\n",
       "      <td>Matem√°tica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boa tarde! Qual a rela√ß√£o das mitoc√¥ndrias com...</td>\n",
       "      <td>Biologia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto     materia  label\n",
       "0  ol√°, como s√£o formadas as cavernas? e as estal...     Qu√≠mica      0\n",
       "1  Qual a diferen√ßa entre a gordura animal e a go...    Biologia      1\n",
       "2  Como funciona a rela√ß√£o do √¢ngulo externo do t...  Matem√°tica      2\n",
       "3  (UESB BA/2017) Sejam dois conjuntos n√£o vazios...  Matem√°tica      2\n",
       "4  Boa tarde! Qual a rela√ß√£o das mitoc√¥ndrias com...    Biologia      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionando uma coluna extra para que seja mais f√°cil a contagem de perguntas de X materia\n",
    "df_perguntas['label'] = pd.factorize(df_perguntas.materia)[0]\n",
    "df_perguntas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baixando o modelo BERTimbau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-large-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast  # Classe necessaria para o tokenizador, que usaremos para tratamento do texto\n",
    "from transformers import BertForSequenceClassification  # Classe necessaria para importar o modelo\n",
    "from transformers import pipeline\n",
    "\n",
    "# Baixar o modelo pode demorar um pouco\n",
    "bertimbau = BertForSequenceClassification.from_pretrained('neuralmind/bert-large-portuguese-cased', num_labels=NUMERO_MATERIAS, id2label=dic_id_para_materia, label2id=dic_materia_para_id)\n",
    "tokenizer = BertTokenizerFast.from_pretrained('neuralmind/bert-large-portuguese-cased', max_lenght=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware a ser utilizado para o treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processador\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "\n",
    "hardware = None\n",
    "\n",
    "# Verifica se e possivel utilizar a placa de video para o treinamento do PyTorch\n",
    "if cuda.is_available(): hardware = 'cuda'\n",
    "else: hardware = 'cpu'\n",
    "\n",
    "# Printa o hardware que sera utilizado de uma forma mais clara ao usuario\n",
    "print('Placa de video' if hardware == 'cuda' else 'Processador')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informacoes sobre o modelo BERTimbau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29794, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Informacoes sobre o modelo BERTimbau\n",
    "bertimbau.to(hardware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando nosso modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro vamos subdividir e preparar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_perguntas.drop(columns=['materia', 'label'])\n",
    "y = df_perguntas.drop(columns=['materia', 'texto'])\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.30, shuffle=True)\n",
    "\n",
    "X_treino = list(X_treino['texto'])\n",
    "X_teste = list(X_teste['texto'])\n",
    "\n",
    "y_treino = list(y_treino['label'])\n",
    "y_teste = list(y_teste['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino tem 6 quest√µes de Qu√≠mica\n",
      "Treino tem 7 quest√µes de Biologia\n",
      "Treino tem 9 quest√µes de Matem√°tica\n",
      "Treino tem 6 quest√µes de Hist√≥ria\n",
      "Treino tem 7 quest√µes de Literatura\n",
      "Treino tem 7 quest√µes de F√≠sica\n"
     ]
    }
   ],
   "source": [
    "for label,(chave, materia) in enumerate(dic_id_para_materia.items()):\n",
    "    print(f\"Treino tem {y_treino.count(chave)} quest√µes de {materia}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino tem 5 quest√µes de Qu√≠mica\n",
      "Treino tem 3 quest√µes de Biologia\n",
      "Treino tem 1 quest√µes de Matem√°tica\n",
      "Treino tem 4 quest√µes de Hist√≥ria\n",
      "Treino tem 3 quest√µes de Literatura\n",
      "Treino tem 3 quest√µes de F√≠sica\n"
     ]
    }
   ],
   "source": [
    "for label,(chave, materia) in enumerate(dic_id_para_materia.items()):\n",
    "    print(f\"Treino tem {y_teste.count(chave)} quest√µes de {materia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_treino = tokenizer(X_treino, truncation=True, padding=True, max_length=512)\n",
    "tokens_teste = tokenizer(X_teste, truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PacoteDados(Dataset):\n",
    "    def __init__(self, tokens, labels):\n",
    "        self.tokens = tokens\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, indice):\n",
    "        item = {key: torch.tensor(val[indice]) for key, val in self.tokens.items()}\n",
    "        item['label'] = torch.tensor(self.labels[indice])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacote_treino = PacoteDados(tokens_treino, y_treino)\n",
    "pacote_teste = PacoteDados(tokens_teste, y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "argumentos_treino = TrainingArguments(\n",
    "    #* Diretorio de saida serve para guardar previsoes e checkpoints do modelo\n",
    "    output_dir = \"../Model/Dados\", \n",
    "    overwrite_output_dir = True,\n",
    "    do_train = True,\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    #* do_eval nos diz se o modelo deve ou nao fazer a etapa de validacao\n",
    "    do_eval = True,\n",
    "    \n",
    "    #* Numero de epocas, normalmente 3\n",
    "    num_train_epochs = 8, # Melhor resultado variando entre 8 e 10\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    # Number of steps used for a linear warmup\n",
    "    #warmup_steps = 100,                \n",
    "    #weight_decay = 0.01,\n",
    "    logging_strategy = 'steps',\n",
    "\n",
    "    #* Diretorio para armazenamento de Logs                 \n",
    "    logging_dir = '../Model/Logs/',            \n",
    "    #logging_steps = 50,\n",
    "    evaluation_strategy = \"steps\",\n",
    "    #eval_steps = 50,\n",
    "    save_strategy = \"steps\", \n",
    "    fp16 = True if hardware == 'cuda' else False,\n",
    "    load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calcular_metricas(previsoes):\n",
    "    labels = previsoes.label_ids\n",
    "    \n",
    "    previsao = previsoes.predictions.argmax(-1)\n",
    "    \n",
    "    precisao, recall, f1, _ = precision_recall_fscore_support(labels, previsao, average='macro')\n",
    "    acuracia = accuracy_score(labels, previsao)\n",
    "    \n",
    "    return {\n",
    "        'Acuracia': acuracia,\n",
    "        'F1': f1,\n",
    "        'Precisao': precisao,\n",
    "        'Recall': recall\n",
    "    }\n",
    "\n",
    "def predizer(texto):\n",
    "    # Faz o texto ser tokenzinado e transformado em tensores para o PyTorch\n",
    "    inputs = tokenizer(texto, padding=True, truncation=True, max_length=512, return_tensors='pt').to(hardware)\n",
    "\n",
    "    # Passa os tensores como input para o nosso modelo\n",
    "    resultado = bertimbau(inputs)\n",
    "\n",
    "    # Primeiro pegamos da tupla resultado somente o tensor que queremos na posicao 0\n",
    "    # Entao aplicamos o softmax para que possamos ter as probabilidades de cada classe\n",
    "    probabilidades = resultado[0].softmax(1)\n",
    "\n",
    "    # Assim conseguimos pegar o maior valor das probabilidades, ou seja a classe mais provavel\n",
    "    id_label_prevista = probabilidades.argmax()\n",
    "\n",
    "    # Entao podemos pegar a label prevista atraves das configuracoes que colocamos ao definir o modelo\n",
    "    # Assim usamos o ID obtido para conseguir o nome da materia prevista\n",
    "    label_prevista = bertimbau.config.id2label[id_label_prevista.item()]\n",
    "\n",
    "    return probabilidades, id_label_prevista, label_prevista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "treinador = Trainer(\n",
    "    model = bertimbau,\n",
    "    args = argumentos_treino,\n",
    "    train_dataset = pacote_treino,\n",
    "    eval_dataset= pacote_teste,\n",
    "    compute_metrics = calcular_metricas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [11:48<00:00, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 708.2474, 'train_samples_per_second': 0.474, 'train_steps_per_second': 0.068, 'train_loss': 0.7534275849660238, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=48, training_loss=0.7534275849660238, metrics={'train_runtime': 708.2474, 'train_samples_per_second': 0.474, 'train_steps_per_second': 0.068, 'train_loss': 0.7534275849660238, 'epoch': 8.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treinador.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.5556139349937439,\n",
       " 'test_Acuracia': 0.8421052631578947,\n",
       " 'test_F1': 0.8277777777777776,\n",
       " 'test_Precisao': 0.85,\n",
       " 'test_Recall': 0.8777777777777778,\n",
       " 'test_runtime': 8.282,\n",
       " 'test_samples_per_second': 2.294,\n",
       " 'test_steps_per_second': 0.241}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treinador.predict(pacote_teste).metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Model/Modelo\\\\tokenizer_config.json',\n",
       " '../Model/Modelo\\\\special_tokens_map.json',\n",
       " '../Model/Modelo\\\\vocab.txt',\n",
       " '../Model/Modelo\\\\added_tokens.json',\n",
       " '../Model/Modelo\\\\tokenizer.json')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_modelo = \"../Model/Modelo\"\n",
    "#! Somente salvar se o modelo for melhor que o anterior\n",
    "treinador.save_model(path_modelo)\n",
    "tokenizer.save_pretrained(path_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_modelo = \"../Model/Modelo\"\n",
    "\n",
    "modelo = BertForSequenceClassification.from_pretrained(path_modelo)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(path_modelo)\n",
    "classificador = pipeline(\"text-classification\", model=modelo, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Hist√≥ria', 'score': 0.46252572536468506}]\n",
      "[{'label': 'Matem√°tica', 'score': 0.9501256346702576}]\n",
      "[{'label': 'Qu√≠mica', 'score': 0.802685558795929}]\n",
      "[{'label': 'Literatura', 'score': 0.9064043164253235}]\n",
      "[{'label': 'F√≠sica', 'score': 0.8219466209411621}]\n"
     ]
    }
   ],
   "source": [
    "print(classificador(\"Imp√©rio romano\"))\n",
    "print(classificador(\"Me ajude a fazer essa conta: x2 + y2 = 4 + 4\"))\n",
    "print(classificador(\"Modelo at√¥mico\"))\n",
    "print(classificador(\"Quando ocorreu o Trovadorismo?\"))\n",
    "print(classificador(\"Qual a velocidade m√©dia de uma pessoa que anda a 2km/h?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B√¥nus do desafio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "espacamento = 60\n",
    "\n",
    "df_perguntas = pd.read_csv(\"../Dados/dados.csv\")\n",
    "materias = df_perguntas['materia'].unique().tolist()\n",
    "del df_perguntas\n",
    "\n",
    "def pegarMateria():\n",
    "    materia = None\n",
    "    \n",
    "    while materia == None:\n",
    "        for i in range(len(materias)):\n",
    "            print(f\"{i} - {materias[i]}\".rjust(espacamento), flush=True)\n",
    "        \n",
    "        materia = int(input())\n",
    "\n",
    "        if (materia >= len(materias) and materia < 0):\n",
    "            materia = None\n",
    "            print(\"Nenhuma mat√©ria encontrada com esse numero\")\n",
    "    \n",
    "    return materia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------* Menu *--------------------------\n",
      "1 - Fazer pergunta -----------------------------------------\n",
      "0 - Sair ---------------------------------------------------\n",
      "------------------- Digite sua pergunta --------------------\n",
      "------------------------------------------------------------\n",
      "------------ Agora nos diga o numero da mat√©ria ------------\n",
      "                                                 0 - Qu√≠mica\n",
      "                                                1 - Biologia\n",
      "                                              2 - Matem√°tica\n",
      "                                                3 - Hist√≥ria\n",
      "                                              4 - Literatura\n",
      "                                                  5 - F√≠sica\n",
      "------------------------------------------------------------\n",
      "Mat√©ria original: Hist√≥ria\n",
      "Mat√©ria prevista: Hist√≥ria\n",
      "Tempo de resposta: 0.14891679999709595\n",
      "A IA acertou a mat√©ria!\n",
      "\n",
      "\n",
      "--------------------------* Menu *--------------------------\n",
      "1 - Fazer pergunta -----------------------------------------\n",
      "0 - Sair ---------------------------------------------------\n",
      "\n",
      "\n",
      "Fim da execu√ß√£o!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "quebrarWhile = False\n",
    "opcao = None\n",
    "\n",
    "while quebrarWhile == False:\n",
    "    print(\"* Menu *\".center(espacamento, '-'))\n",
    "    print(\"1 - Fazer pergunta \".ljust(espacamento, '-'))\n",
    "    print(\"0 - Sair \".ljust(espacamento, '-'), flush=True)\n",
    "    opcao = int(input())\n",
    "\n",
    "    if opcao == 0: quebrarWhile = True\n",
    "    elif opcao == 1:\n",
    "        print(\" Digite sua pergunta \".center(espacamento, '-'), flush=True)\n",
    "        texto = input()\n",
    "\n",
    "        print(\"\".center(espacamento, '-'))\n",
    "        print(\" Agora nos diga o numero da mat√©ria \".center(espacamento, '-'), flush=True)\n",
    "        indice_materia = pegarMateria()\n",
    "\n",
    "        tempo_inicio = time.perf_counter()\n",
    "        resultado = classificador(texto)[0]\n",
    "        tempo_fim = time.perf_counter()\n",
    "\n",
    "        print(\"\".center(espacamento, \"-\"))\n",
    "        print(f\"Mat√©ria original: {materias[indice_materia]}\")\n",
    "        print(f\"Mat√©ria prevista: {resultado['label']}\")\n",
    "        print(f\"Tempo de resposta: {tempo_fim - tempo_inicio} segundos\")\n",
    "\n",
    "        if resultado['label'] == materias[indice_materia]:\n",
    "            print(\"A IA acertou a mat√©ria!\")\n",
    "        else:\n",
    "            print(\"A IA errou a mat√©ria, talvez precise de um melhor treinamento\")\n",
    "        \n",
    "\n",
    "    else: print(f\"Op√ß√£o {opcao} n√£o existe no Menu\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Fim da execu√ß√£o!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
